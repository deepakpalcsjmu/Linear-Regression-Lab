{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b62a01",
   "metadata": {},
   "source": [
    "# Assignment 1  \n",
    "## Comprehensive Study of Linear Regression Models (Manual Implementation)\n",
    "\n",
    "This notebook performs regression analysis **without using any ML library**.\n",
    "Models implemented manually:\n",
    "- Simple Linear Regression\n",
    "- Multiple Linear Regression\n",
    "- Polynomial Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "print(data.describe())\n",
    "print(data.isnull().sum())\n",
    "print(data.corr())\n",
    "\n",
    "data.hist(figsize=(10,8))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n===== SIMPLE LINEAR REGRESSION =====\")\n",
    "\n",
    "x = data['Feature1'].values\n",
    "y = data['Target'].values\n",
    "\n",
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "b1 = np.sum((x-x_mean)*(y-y_mean)) / np.sum((x-x_mean)**2)\n",
    "b0 = y_mean - b1*x_mean\n",
    "\n",
    "print(\"Slope:\", b1)\n",
    "print(\"Intercept:\", b0)\n",
    "\n",
    "y_pred_simple = b0 + b1*x\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,y_pred_simple,color='red')\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n===== MULTIPLE LINEAR REGRESSION =====\")\n",
    "\n",
    "X = data[['Feature1','Feature2','Feature3']].values\n",
    "y = data['Target'].values\n",
    "\n",
    "X_b = np.c_[np.ones((len(X),1)), X]\n",
    "\n",
    "theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "print(\"Coefficients:\", theta)\n",
    "\n",
    "y_pred = X_b.dot(theta)\n",
    "\n",
    "def mse(y, pred):\n",
    "    return np.mean((y-pred)**2)\n",
    "\n",
    "def rmse(y, pred):\n",
    "    return np.sqrt(mse(y,pred))\n",
    "\n",
    "def r2(y,pred):\n",
    "    ss_total = np.sum((y-np.mean(y))**2)\n",
    "    ss_res = np.sum((y-pred)**2)\n",
    "    return 1 - ss_res/ss_total\n",
    "\n",
    "print(\"MSE:\", mse(y,y_pred))\n",
    "print(\"RMSE:\", rmse(y,y_pred))\n",
    "print(\"R2:\", r2(y,y_pred))\n",
    "\n",
    "print(\"\\n===== POLYNOMIAL REGRESSION =====\")\n",
    "\n",
    "x_poly = data['Feature1'].values\n",
    "X_poly = np.c_[np.ones(len(x_poly)), x_poly, x_poly**2]\n",
    "\n",
    "theta_poly = np.linalg.inv(X_poly.T.dot(X_poly)).dot(X_poly.T).dot(y)\n",
    "y_pred_poly = X_poly.dot(theta_poly)\n",
    "\n",
    "print(\"Polynomial R2:\", r2(y,y_pred_poly))\n",
    "\n",
    "print(\"\\n===== RIDGE REGRESSION =====\")\n",
    "\n",
    "lam = 1\n",
    "I = np.eye(X_b.shape[1])\n",
    "theta_ridge = np.linalg.inv(X_b.T.dot(X_b)+lam*I).dot(X_b.T).dot(y)\n",
    "\n",
    "print(\"Ridge coefficients:\", theta_ridge)\n",
    "\n",
    "print(\"\\n===== LASSO REGRESSION =====\")\n",
    "\n",
    "theta_lasso = np.zeros(X_b.shape[1])\n",
    "lr = 0.0001\n",
    "lam = 0.1\n",
    "\n",
    "for _ in range(1000):\n",
    "    pred = X_b.dot(theta_lasso)\n",
    "    error = pred - y\n",
    "    grad = X_b.T.dot(error)/len(y)\n",
    "    theta_lasso -= lr*(grad + lam*np.sign(theta_lasso))\n",
    "\n",
    "print(\"Lasso coefficients:\", theta_lasso)\n",
    "\n",
    "residuals = y - y_pred\n",
    "\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
